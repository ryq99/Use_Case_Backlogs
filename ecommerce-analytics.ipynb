{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nimport plotly.offline as py\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\n\nHTML('''<script>\ncode_show=true; \nfunction code_toggle() {\n if (code_show){\n $('div.input').hide();\n } else {\n $('div.input').show();\n }\n code_show = !code_show\n} \n$( document ).ready(code_toggle);\n</script>\n<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Goal"},{"metadata":{},"cell_type":"markdown","source":"#### This project is based on a e-commerce clothing startup. \n#### The goal is to explore customers and sales trends and behaviors to give the business some insights and strategies to boost sales. "},{"metadata":{},"cell_type":"markdown","source":"### Contents"},{"metadata":{},"cell_type":"markdown","source":"#### Major analyses are as follows:\n1. Sales Trend Analysis\n2. Sales Funnel Analysis \n3. Product Analysis\n4. Promotion Analysis\n5. Customer Analysis\n    - Churn\n    - Retention\n    - RFM\n    - Clustering"},{"metadata":{},"cell_type":"markdown","source":"### Key Findings"},{"metadata":{},"cell_type":"markdown","source":"#### Website\n\n1. Traffic strongly follows the 4 seasons. At the start of every season, traffic goes up. \n2. Traffic also follows holiday seasons, for example, Thanksgiving Day.\n3. Traffic is correlated with the number of placed orders, the lower the sales funnel, the higher correlation will be.  \n4. The sales funnel conversion rates in general is healthy. The one from detail view to add-to-cart is only 10%, which is the lowest."},{"metadata":{},"cell_type":"markdown","source":"#### Products\n\n1. Different product types have large sales during the start of corresponding seasons, for example, dress has large sales from June to August. \n2. Some most popular combos of two product types are *maxi-pants*, *tunic-pullover*, *mini-croptop*, *jumpsuit-bodysuit*  \n3. Some least popular combos of two product types are *trousers-maxi*, *trousers-midi*, *top-accessory*, *top-maxi*, *top-midi* \n4. Products bundlings within the same orders are *romper-blouse* , *sweater-jacket* , *shorts-blouse*  \n5. Discounts is correlated with order price (significance test not conducted)"},{"metadata":{},"cell_type":"markdown","source":"#### Customers\n\n1. 25% of customers are missing full names, which is the most important shipping/billing information\n2. Customers are leaving after sign-ups, some without any purchase and some with only 1 purchase\n3. There is a group of loyal customers"},{"metadata":{},"cell_type":"markdown","source":"### Recommendations"},{"metadata":{},"cell_type":"markdown","source":"#### Website\n\n* Improve website conversion rates:\n    - Product detail page\n    - Personalized and nonpersonalized recommendations\n    - Page contents & variations"},{"metadata":{},"cell_type":"markdown","source":"#### Products\n* Alter inventories according to seasonality\n* Promotions on holiday seasons\n* Product bundling according to purchase combinations\n* Larger product discounts"},{"metadata":{},"cell_type":"markdown","source":"#### Customers\n* Focus on retention by getting customer feedbacks\n* Target on loyal customers"},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\n# customer => website (traffic) => product/product sku => order/order items => transaction\ncustomers = pd.read_csv(r'/kaggle/input/ecommerce-clothing-store/customers.csv').rename(columns={'id':'customer_id', 'created_at':'customer_created_at'})\ntraffic = pd.read_csv(r'/kaggle/input/ecommerce-clothing-store/traffic.csv').drop(columns=['index'])\nproducts = pd.read_csv(r'/kaggle/input/ecommerce-clothing-store/products.csv').rename(columns={'id':'product_id', 'title':'product_title', 'created_at':'product_created_at', 'published_at':'product_published_at'})\nprod_sku = pd.read_csv(r'/kaggle/input/ecommerce-clothing-store/products_skus.csv').rename(columns={'id':'product_sku_id', 'created_at':'sku_created_at'})\norders = pd.read_csv(r'/kaggle/input/ecommerce-clothing-store/orders.csv').rename(columns={'id':'order_id', 'created_at':'order_created_at', 'closed_at':'order_closed_at', 'cancelled_at':'order_cancelled_at', 'processed_at': 'order_processed_at'})\nord_item = pd.read_csv(r'/kaggle/input/ecommerce-clothing-store/orders_items.csv').rename(columns={'id':'order_product_id'})\ntransactions = pd.read_csv(r'/kaggle/input/ecommerce-clothing-store/transactions.csv').rename(columns={'id':'transaction_id', 'created_at':'transaction_created_at', 'status':'transaction_status', 'kind':'transaction_kind', 'amount':'transaction_amount'})\n\ncol_dict = {}\ncol_dict['customers'] = customers.columns.tolist()\ncol_dict['traffic'] = traffic.columns.tolist()\ncol_dict['products'] = products.columns.tolist()\ncol_dict['prod_sku'] = prod_sku.columns.tolist()\ncol_dict['orders'] = orders.columns.tolist()\ncol_dict['ord_item'] = ord_item.columns.tolist()\ncol_dict['transactions'] = transactions.columns.tolist()\n\nprint('customers:', col_dict['customers'])\nprint('traffic:', col_dict['traffic'])\nprint('products:', col_dict['products'])\nprint('prod_sku:', col_dict['prod_sku'])\nprint('orders:', col_dict['orders'])\nprint('ord_item:', col_dict['ord_item'])\nprint('transactions:', col_dict['transactions'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### No. Customers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are {} customers, {} don't have full names, which is {:.2%}.\".format(customers['customer_id'].nunique(), customers['full_name'].isnull().sum(), customers['full_name'].isnull().sum() / customers['customer_id'].nunique()))\nprint(\"{} are unique full names and {} are duplicates.\".format(customers['full_name'].nunique(), customers['customer_id'].nunique() - customers['full_name'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Customers with Different # Orders "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncustomer_order_ratios = (pd.merge(customers,\n                                  orders, \n                                  on='customer_id', \n                                  how='left')\n                         .groupby(['customer_id'])['order_id'].nunique()\n                         .reset_index()\n                         .rename(columns={'order_id':'num_orders'}))['num_orders'].value_counts().reset_index().rename(columns={'num_orders':'num_customers','index':'num_orders'})\n\n\ncustomer_order_ratios['ratio_customers'] = np.round(customer_order_ratios['num_customers'] / customer_order_ratios['num_customers'].sum(), 4)\nprint('Ratio of customers having 0 order = {} ({:.2%})'.format(customer_order_ratios.loc[lambda x: x['num_orders'] == 0]['num_customers'].values[0], customer_order_ratios.loc[lambda x: x['num_orders'] == 0]['ratio_customers'].values[0]))\nprint('Ratio of customers having 1 order = {} ({:.2%})'.format(customer_order_ratios.loc[lambda x: x['num_orders'] == 1]['num_customers'].values[0], customer_order_ratios.loc[lambda x: x['num_orders'] == 1]['ratio_customers'].values[0]))\ncustomer_order_ratios","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Traffic (Pageviews):"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.histplot(data=traffic, x='page_views', bins=50, kde=True)\nprint('Avg. daily # pageviews = {:.0f}'.format(traffic['page_views'].mean()))\nprint('Medium. daily # pageviews = {:.0f}'.format(traffic['page_views'].median()))\nprint('# outliers = {} {}'.format(traffic.loc[np.abs(stats.zscore(traffic['page_views'])) > 3, 'page_views'].count(), traffic.loc[np.abs(stats.zscore(traffic['page_views'])) > 3, 'page_views'].tolist()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### No. Product Detail Pageviews:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.histplot(data=traffic, x='product_detail_views', bins=50, kde=True)\nprint('Avg. daily # product detail pageviews = {:.0f}'.format(traffic['product_detail_views'].mean()))\nprint('Median daily # product detail pageviews = {:.0f}'.format(traffic['product_detail_views'].median()))\nprint('# outliers = {} {}'.format(traffic.loc[np.abs(stats.zscore(traffic['product_detail_views'])) > 3, 'product_detail_views'].count(), traffic.loc[np.abs(stats.zscore(traffic['product_detail_views'])) > 3, 'product_detail_views'].tolist()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### No. Add2Carts:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.histplot(data=traffic, x='product_adds_to_carts', bins=50, kde=True)\nprint('Avg. daily # add-to-carts = {:.0f}'.format(traffic['product_adds_to_carts'].mean()))\nprint('Median daily # add-to-carts = {:.0f}'.format(traffic['product_adds_to_carts'].median()))\nprint('# outliers = {} {}'.format(traffic.loc[np.abs(stats.zscore(traffic['product_adds_to_carts'])) > 3, 'product_adds_to_carts'].count(), traffic.loc[np.abs(stats.zscore(traffic['product_adds_to_carts'])) > 3, 'product_adds_to_carts'].tolist()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### No. Checkouts:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(data=traffic, x='product_checkouts', bins=50, kde=True)\nprint('Avg. daily # checkouts = {:.0f}'.format(traffic['product_checkouts'].mean()))\nprint('Median daily # checkouts = {:.0f}'.format(traffic['product_checkouts'].median()))\nprint('# outliers = {} {}'.format(traffic.loc[np.abs(stats.zscore(traffic['product_checkouts'])) > 3, 'product_checkouts'].count(), traffic.loc[np.abs(stats.zscore(traffic['product_checkouts'])) > 3, 'product_checkouts'].tolist()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sessions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,10))\nsns.histplot(data=traffic, x='sessions', ax=ax1, bins=50, kde=True)\nax1.set_title('# sessions')\nsns.histplot(data=traffic, x='avg_session_in_s', ax=ax2, bins=50, kde=True)\nax2.set_title('session duration in seconds')\nprint('Avg. daily # sessions = {:.0f}'.format(traffic['sessions'].mean()))\nprint('Median daily # sessions = {:.0f}'.format(traffic['sessions'].median()))\nprint('# outliers = {} {}'.format(traffic.loc[np.abs(stats.zscore(traffic['sessions'])) > 3, 'sessions'].count(), traffic.loc[np.abs(stats.zscore(traffic['sessions'])) > 3, 'sessions'].tolist()))\nprint('\\n')\nprint('Avg. of daily average session in seconds = {:.2f}'.format(traffic['avg_session_in_s'].mean()))\nprint('Median. of daily average session in seconds = {:.2f}'.format(traffic['avg_session_in_s'].median()))\nprint('# outliers = {} {}'.format(traffic.loc[np.abs(stats.zscore(traffic['avg_session_in_s'])) > 3, 'avg_session_in_s'].count(), np.round(traffic.loc[np.abs(stats.zscore(traffic['avg_session_in_s'])) > 3, 'avg_session_in_s'].tolist(), 2)))\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Product Types:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} products and {} product types.'.format(products['product_id'].nunique(), products['product_type'].nunique()))\nprint('* Hooide==hoodie, Tousers==Trousers, and mixed-cases to be improved...')\n\nproducts['product_type'] = products['product_type'].str.lower()\nproducts.loc[lambda x: x['product_type'] == 'tousers', 'product_type'] = 'trousers'\nproducts.loc[lambda x: x['product_type'] == 'hooide', 'product_type'] = 'hoodie'\nplt.figure(figsize=(10, 10))\nsns.barplot(data=products.groupby(['product_type'])['product_id'].count().reset_index().rename(columns={'product_id':'num_products'}).sort_values(by=['num_products'], ascending=False), \n            x='num_products',\n            y='product_type');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Product SKU (Stock Keeping Unit):"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} SKUs, which means some products have multiple SKUs.'.format(prod_sku['sku'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(10, 10))\nsns.boxplot(data=pd.merge(products, prod_sku.loc[lambda x: x['price'] != x['price'].max()], on='product_id'), y='price', x='product_type', ax=ax1)\nax1.set_xticklabels(labels=ax1.get_xticklabels(), rotation=30)\nax1.hlines(y=prod_sku['price'].median(), xmin=min(ax1.get_xlim()), xmax=max(ax1.get_xlim()), linestyle='dashed', linewidth=2, color='purple')\nax1.hlines(y=prod_sku['price'].quantile(0.25), xmin=min(ax1.get_xlim()), xmax=max(ax1.get_xlim()), linestyle='dashed', linewidth=2, color='red')\nax1.hlines(y=prod_sku['price'].quantile(0.75), xmin=min(ax1.get_xlim()), xmax=max(ax1.get_xlim()), linestyle='dashed', linewidth=2, color='green')\nfig.tight_layout()\n\nprint('- Min price = {:.2f}'.format(prod_sku['price'].min()))\nprint('- Upper quartile price = {:.2f}'.format(prod_sku['price'].quantile(0.75)))\nprint('- Median price = {:.2f}'.format(prod_sku['price'].median()))\nprint('- Lower quartile price = {:.2f}'.format(prod_sku['price'].quantile(0.25)))\nprint('- Max price = {:.2f}'.format(prod_sku['price'].max()))\nprint('There are {} outliers: {}'.format(prod_sku.loc[np.abs(stats.zscore(prod_sku['price'])) > 3].shape[0], pd.merge(products, prod_sku, on='product_id').loc[lambda x: np.abs(stats.zscore(x['price'])) > 3, ['product_type', 'price']].values.tolist()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Orders:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} orders.'.format(orders['order_id'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(orders[['order_created_at', 'order_processed_at', 'order_closed_at', 'order_cancelled_at']].notnull().drop_duplicates().reset_index(drop=True), '\\n')\nprint(\"Order creation & process date doesn't have NaNs, and theoretically order close date should be later than order cancel date.\")\nprint('* There are {} record having close date before cancel date.'.format(orders.loc[lambda x: x['order_closed_at'] < x['order_cancelled_at']].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"When orders haven't been closed yet, most of them are not fulfilled or only partially fulfilled: \\n{}\".format(orders.loc[lambda x: x['order_closed_at'].isnull()]['fulfillment_status'].value_counts(dropna=False).to_dict()))\nprint(\"If they are fulfilled but still not closed yet, the financial status are: \\n{}\".format(orders.loc[lambda x: x['order_closed_at'].isnull() & (x['fulfillment_status'] == 'fulfilled')]['financial_status'].value_counts(dropna=False).to_dict()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fulfillment Status:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.barplot(data=orders['fulfillment_status'].value_counts(dropna=True).reset_index().rename(columns={'index':'fulfillment_status', 'fulfillment_status':'frequency'}), x='frequency', y='fulfillment_status');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Financial Status:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.barplot(data=orders['financial_status'].value_counts(dropna=True).reset_index().rename(columns={'index':'financial_status', 'financial_status':'frequency'}), x='frequency', y='financial_status');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Order Size (# items/order):"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nprint('Some stats for # items/order: \\n{}'.format(pd.merge(products, ord_item, on='product_id').groupby(['order_id'])['quantity'].sum().reset_index()['quantity'].describe()))\nsns.histplot(data=pd.merge(products, ord_item, on='product_id').groupby(['order_id'])['quantity'].sum().reset_index(), x='quantity', bins=50);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('For those orders having at least 2 items:')\norder_over_2 = (pd.merge(products, ord_item, on='product_id').groupby(['order_id'])['quantity'].sum().reset_index().loc[lambda x: x['quantity'] >= 2]['order_id'])\nproduct_bundle = pd.merge(products, ord_item, on='product_id')\nproduct_bundle = pd.pivot_table(product_bundle.loc[lambda x: x['order_id'].isin(order_over_2)],\n               index='order_id',\n               columns=['product_type'],\n               values=['quantity'],\n               aggfunc='sum',\n               fill_value=0).reset_index()\nproduct_bundle.columns[1]\nproduct_bundle.columns = [product_bundle.columns[0][0]] + [product_bundle.columns[i][1] for i in range(1, len(product_bundle.columns))]\nproduct_bundle = product_bundle.set_index('order_id')\n\nproduct_bundle['item_freq'] = product_bundle.apply(lambda x: {col:x[col] for col in product_bundle.columns if x[col] > 0}, axis=1)\nproduct_bundle.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Order Price:"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = orders[['total_line_items_price', 'total_discounts', 'subtotal_price', 'shipping_rate', 'total_price']]\nfig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows=5, ncols=1, figsize=(10, 10))\n\nsns.histplot(data=temp, x='total_line_items_price', ax=ax1, bins=50, kde=True, color='red')\nsns.histplot(data=temp, x='total_discounts', ax=ax2, bins=50, kde=True, color='orange')\nsns.histplot(data=temp, x='subtotal_price', ax=ax3, bins=50, kde=True, color='green')\nsns.histplot(data=temp, x='shipping_rate', ax=ax4, bins=50, kde=True, color='blue')\nsns.histplot(data=temp, x='total_price', ax=ax5, bins=50, kde=True, color='purple');\n\nax1.set_xlabel('total_line_items_price (+)')\nax2.set_xlabel('total_discounts (-)')\nax3.set_xlabel('subtotal_price (+)')\nax4.set_xlabel('shipping_rate (+)')\nax5.set_xlabel('total_price (+)')\n\nfig.tight_layout()\nplt.xlim((0, 1050));\nprint('The order price follows this order: {}'.format(' ==> '.join(temp.columns.tolist())))\nprint('* (+) means add-on price, (-) means deduct price.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Product Total Items Price:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(15, 10), gridspec_kw={'height_ratios': [1, 9]})\nfig, ax2 = plt.subplots(figsize=(15, 10))\n\n#sns.boxplot(data=ord_item, x='price', ax=ax1)\n#ax1.set_xlabel('overall item price')\nsns.barplot(data=(pd.merge(products, \n                           ord_item, \n                           on='product_id')\n                  .groupby(['product_type'])\n                  .apply(lambda x: (x['quantity'] * x['price']).sum())\n                  .reset_index()\n                  .rename(columns={0:'total_price'})\n                  .sort_values(by=['total_price'], ascending=False)), \n            x='total_price', \n            y='product_type', \n            ax=ax2)\n\nax2.set_xlabel('product total items price')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Transactions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.merge(orders, transactions, on='order_id')[['total_price', 'transaction_amount', 'transaction_kind', 'transaction_status']]\nprint('Order total price == transaction price? There are {} not equal.'.format(temp.loc[lambda x: x['total_price'] != x['transaction_amount']].shape[0]))\ntemp.loc[lambda x: x['total_price'] != x['transaction_amount']]['transaction_kind'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data=temp.groupby(['transaction_kind'])['transaction_amount'].count().reset_index().rename(columns={'transaction_amount':'freq'}), y='transaction_kind', x='freq');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sales Trend Analysis"},{"metadata":{},"cell_type":"markdown","source":"* Sales trend by daily traffic"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_trend_by_traffic = traffic.copy()\nsales_trend_by_traffic['y_m'] = sales_trend_by_traffic['date_day'].apply(lambda x: x[:7])\nfig, ax = plt.subplots(figsize=(20, 5))\nplt.ylim((0, 250000))\n# pageview - time\nsns.lineplot(data=sales_trend_by_traffic.sort_values(by=['date_day']), x='date_day', y='page_views', ax=ax, label='page view')\n# sessions - time\nsns.lineplot(data=sales_trend_by_traffic.sort_values(by=['date_day']), x='date_day', y='sessions', ax=ax, label='session')\n# prduct detail view - time\nsns.lineplot(data=sales_trend_by_traffic.sort_values(by=['date_day']), x='date_day', y='product_detail_views', ax=ax, label='detail view')\n# product add to cart - time\nsns.lineplot(data=sales_trend_by_traffic.sort_values(by=['date_day']), x='date_day', y='product_adds_to_carts', ax=ax, label='add to cart')\n# product checkouts - time\nsns.lineplot(data=sales_trend_by_traffic.sort_values(by=['date_day']), x='date_day', y='product_checkouts', ax=ax, label='checkout')\n\nplt.xticks(ticks=sales_trend_by_traffic.reset_index().groupby(['y_m'])['index'].first().tolist(), labels=sales_trend_by_traffic.reset_index().groupby(['y_m'])['index'].first().index.tolist(), rotation=30);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Sales trend by daily sold items"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_trend_by_item = (pd.merge(orders.loc[lambda x: x['fulfillment_status'] == 'fulfilled'], \n                                transactions.loc[lambda x: x['transaction_status'] == 'success'], \n                                on='order_id')\n                       .merge(ord_item, on='order_id')\n                       .merge(products, on='product_id')\n                       .groupby(['order_created_at', 'product_type'])[['quantity']].sum()\n                       .reset_index())\nsales_trend_by_item['y_m'] = sales_trend_by_item['order_created_at'].apply(lambda x: x[:7])\n\n# now we split the product types into 5 tiers based on popularity\nt1 = ['top', 'dress', 'trousers', 'jacket', 'skirt'] \nt2 = ['shirts', 'sweater', 'blazer', 'mini', 'blouse']\nt3 = ['shorts', 'hoodie', 'jumpsuit', 'crop top', 'tank'] \nt4 = ['bodysuit', 'cardigan', 'bomber', 'pants', 'romper']\nt5 = ['accessory', 'midi', 'pullover', 'maxi', 'gift card', 'tunic']\n      \nfig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows=5, ncols=1, figsize=(20, 20))\nfig.tight_layout()\nsns.lineplot(data=sales_trend_by_item.loc[lambda x: x['product_type'].isin(t1)], x='order_created_at', y='quantity', hue='product_type', ax=ax1, alpha=0.9)\nsns.lineplot(data=sales_trend_by_item.loc[lambda x: x['product_type'].isin(t2)], x='order_created_at', y='quantity', hue='product_type', ax=ax2, alpha=0.9)\nsns.lineplot(data=sales_trend_by_item.loc[lambda x: x['product_type'].isin(t3)], x='order_created_at', y='quantity', hue='product_type', ax=ax3, alpha=0.9)\nsns.lineplot(data=sales_trend_by_item.loc[lambda x: x['product_type'].isin(t4)], x='order_created_at', y='quantity', hue='product_type', ax=ax4, alpha=0.9)\nsns.lineplot(data=sales_trend_by_item.loc[lambda x: x['product_type'].isin(t5)], x='order_created_at', y='quantity', hue='product_type', ax=ax5, alpha=0.9);\n\ndef adjust_xticks(data, t, ax, rotation=15):\n    xticks = data.loc[lambda x: x['product_type'].isin(t)][['order_created_at', 'y_m']].drop_duplicates().reset_index(drop=True).reset_index().groupby(['y_m'])['index'].first().tolist()\n    xticklabels = data.loc[lambda x: x['product_type'].isin(t)]['y_m'].unique().tolist()\n    data = data.reset_index().loc[lambda x: x['product_type'].isin(t)]\n    ax.set_xticks(ticks=xticks)\n    ax.set_xticklabels(labels=xticklabels, \n                       rotation=rotation)\n\nadjust_xticks(sales_trend_by_item, t1, ax1)\nadjust_xticks(sales_trend_by_item, t2, ax2)\nadjust_xticks(sales_trend_by_item, t3, ax3)\nadjust_xticks(sales_trend_by_item, t4, ax4)\nadjust_xticks(sales_trend_by_item, t5, ax5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Sales trend by daily order"},{"metadata":{"trusted":true},"cell_type":"code","source":"# here again, to make sure each order is closed and have brought revenue, we also make sure the it is not a fully refunded order.\nsales_trend_by_order = (pd.merge(transactions, orders, on='order_id')\n                        .loc[lambda x: \n                             (x['fulfillment_status'] == 'fulfilled') & \n                             (x['transaction_status'] == 'success') & \n                             (x['financial_status'] != 'refunded')]\n                        .groupby(['order_created_at'])['order_id'].nunique()\n                        .reset_index()\n                        .rename(columns={'order_id':'num_order'}))\n\nsales_trend_by_order['y_m'] = sales_trend_by_order['order_created_at'].apply(lambda x: x[:7])\n\nplt.figure(figsize=(20, 5))\nsns.lineplot(data=sales_trend_by_order, x='order_created_at', y='num_order');\nplt.xticks(ticks=sales_trend_by_order.reset_index().groupby(['y_m'])['index'].first().tolist(),\n           labels=sales_trend_by_order['y_m'].unique().tolist(),\n           rotation=15);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Traffic-order correlation "},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_traf_order = (traffic\n                  .merge(sales_trend_by_order, \n                         left_on='date_day',\n                         right_on='order_created_at')\n                  .sort_values(by=['date_day']))\n\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(nrows=3, ncols=2, figsize=(12, 15))\nsns.scatterplot(data=cor_traf_order, y='page_views', x='num_order', ax=ax1)\nsns.scatterplot(data=cor_traf_order, y='sessions', x='num_order', ax=ax2)\nsns.scatterplot(data=cor_traf_order, y='product_detail_views', x='num_order', ax=ax3)\nsns.scatterplot(data=cor_traf_order, y='product_adds_to_carts', x='num_order', ax=ax4)\nsns.scatterplot(data=cor_traf_order, y='product_checkouts', x='num_order', ax=ax5);\n\ncor_traf_item = (sales_trend_by_order\n                 .merge(sales_trend_by_item\n                        .groupby(['order_created_at'])['quantity'].sum()\n                        .reset_index(),\n                        on='order_created_at')\n                 .sort_values(by=['order_created_at'])\n                 .rename(columns={'quantity':'items'}))\n\nsns.scatterplot(data=cor_traf_item, y='items', x='num_order', ax=ax6);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(20,5))\nfig.tight_layout()\n#fig.suptitle('The relation between page views and orders', fontsize=40)\ncolor = 'tab:cyan'\nax1.set_xlabel('Time Period', fontsize=28)\nax1.set_ylabel('Page Views', color=color, fontsize=28)\nsns.lineplot(data=cor_traf_order, x='order_created_at', y='page_views', color=color, linewidth=3, ax=ax1)\nax1.tick_params(axis='y', labelcolor=color)\nxticks = cor_traf_order.reset_index().groupby(['y_m'])['index'].first().tolist()\nxlabels = cor_traf_order['y_m'].unique().tolist()\nax1.set_xticks(ticks=xticks)\nax1.set_xticklabels(labels=xlabels, rotation=30)\n\nplt.xticks(size=20)\nplt.yticks(size=20)\n\nax2 = ax1.twinx()\ncolor = 'tab:purple'\nax2.set_ylabel('Orders', color=color, fontsize=28)\nsns.lineplot(data=cor_traf_order, x='order_created_at', y='num_order', color=color, linewidth=3, ax=ax2)\nax2.tick_params(axis='y', labelcolor=color)\nax2.set_xticks(ticks=xticks)\nax2.set_xticklabels(labels=xlabels, rotation=30)\nplt.yticks(size=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sales Funnel Analysis"},{"metadata":{},"cell_type":"markdown","source":"* Overall Conversion Rates"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The conversion rate of placed order to page view is only 0.19%.')\nprint('Through the sales funnel, there is only 10.08% conversion from detail view to add-to-cart, which is relatively the lowest.')\n# conversion table\ncol_order = ['page_views', 'product_detail_views', 'product_adds_to_carts', 'product_checkouts']\noverall_conversion = traffic[col_order].sum().reset_index().rename(columns={'index':'sales_funnel', 0:'traffic'}).loc[lambda x: ~x['sales_funnel'].isin(['sessions', 'avg_session_in_s'])]\n# orders\noverall_orders= orders[['order_id']].count().reset_index().rename(columns={'index':'sales_funnel', 0:'traffic'})\noverall_orders.loc[0, 'sales_funnel'] = 'placed_orders'\n# closed orders\noverall_closed_orders = (orders\n                         .loc[lambda x: \n                              (x['order_id'].isin(transactions.loc[lambda x: x['transaction_status'] == 'success', 'order_id'].tolist())) &\n                              (x['fulfillment_status'] == 'fulfilled')][['order_id']].count()\n                         .reset_index()\n                         .rename(columns={'index':'sales_funnel', 0:'traffic'}))\noverall_closed_orders.loc[0, 'sales_funnel'] = 'closed_orders'\n# profit orders\noverall_profit_orders = (orders\n                         .loc[lambda x: \n                              (x['order_id'].isin(transactions.loc[lambda x: x['transaction_status'] == 'success', 'order_id'].tolist())) &\n                              (x['fulfillment_status'] == 'fulfilled') & \n                              (x['financial_status'] != 'refunded')][['order_id']].count()\n                         .reset_index()\n                         .rename(columns={'index':'sales_funnel', 0:'traffic'}))\noverall_profit_orders.loc[0, 'sales_funnel'] = 'profit_orders'\n\noverall_conversion = pd.concat([overall_conversion, overall_orders, overall_closed_orders, overall_profit_orders], axis=0)\noverall_conversion['prev_lvl_traffic'] = overall_conversion['traffic'].shift(1)\noverall_conversion['conversion_rate'] = np.round(overall_conversion['traffic'] / overall_conversion['prev_lvl_traffic'], 5)\noverall_conversion['conversion_rate_on_pageview'] = np.round(overall_conversion['traffic'] / overall_conversion.loc[lambda x: x['sales_funnel'] == 'page_views', 'traffic'].values, 5)\noverall_conversion","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Product Analysis"},{"metadata":{},"cell_type":"markdown","source":"* Product trend correlations (date level)"},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_order = (pd.merge(ord_item[['order_id', 'product_id', 'price', 'quantity']],\n                       products[['product_id', 'product_type', 'product_created_at','product_published_at']],\n                       on='product_id')\n              .merge(orders[['order_id', 'order_created_at', 'order_closed_at', 'order_cancelled_at', 'total_price', 'shipping_rate', 'subtotal_price', 'total_discounts', 'total_line_items_price']], \n                     on='order_id')\n              .sort_values(by=['order_id', 'product_id']))\n\nprint('Total No. product types =', prod_order['product_type'].nunique())\nprod_by_t = pd.pivot_table(prod_order,\n               index='order_created_at',\n               columns='product_type',\n               values='quantity',\n               aggfunc=lambda x: sum(x),\n               fill_value=0).reset_index().sort_values(by=['order_created_at'])\nprod_by_t.columns = [col.lower().replace(' ', '_') for col in prod_by_t.columns]\n\nplt.figure(figsize=(20, 20))\nsns.heatmap(np.round(prod_by_t.drop(columns=['order_created_at']).corr(), 3), annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Product bundling & combo-2 (correlation between product types)(order level)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nsns.heatmap(product_bundle.drop(columns=['item_freq']).corr(), annot=True, annot_kws={'fontsize':10}, fmt='0.3f');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Market Basket Analysis a.k.a Affinity Analysis (correlation between two products)"},{"metadata":{"trusted":true},"cell_type":"code","source":"concurrence = (pd.merge(ord_item.loc[lambda x: x['fulfillment_status'] == 'fulfilled'], \n                        ord_item.loc[lambda x: x['fulfillment_status'] == 'fulfilled'], \n                        on='order_id')\n               .loc[lambda x: x['product_id_x'] != x['product_id_y']]\n               .groupby(['product_id_x', 'product_id_y'])['order_id'].count()\n               .reset_index()\n               .rename(columns={'order_id':'num_concurrence', \n                                'product_id_x':'product_x', \n                                'product_id_y':'product_y'}))\n\nconcurrence.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_by_product = (ord_item\n                    .groupby(['product_id'])['order_id'].count()\n                    .reset_index()\n                    .rename(columns={'order_id':'num_order'}))\norder_by_product.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basket = pd.merge(concurrence, \n                  order_by_product.rename(columns={'product_id':'product_x'}), \n                  on='product_x')\nbasket['percentage_purchase_together'] = np.round(basket['num_concurrence'] / basket['num_order'], 4)\nbasket.sort_values(by=['percentage_purchase_together'], ascending=False).head(10)\nbasket\nbasket","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Promotion Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_order_ids = np.intersect1d(orders.loc[lambda x: \n                                             (x['financial_status'] != 'refunded') & \n                                             (x['fulfillment_status'] == 'fulfilled'), 'order_id'].tolist(), \n                                  transactions.loc[lambda x: x['transaction_status'] == 'success', 'order_id'].tolist()) \n\nfig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(15, 10))\nfig.tight_layout()\nsns.histplot(orders.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: x['total_discounts'] == 0]['total_line_items_price'], ax=ax1, bins=50, stat='probability', color='red', label='no discounts', kde=True);\nsns.histplot(orders.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: (x['total_discounts'] > 0) & (x['total_discounts'] <= 10)]['total_line_items_price'], ax=ax1, bins=50, stat='probability', color='yellow', label='discounts <= 10', kde=True);\nsns.histplot(orders.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: (x['total_discounts'] > 10) & (x['total_discounts'] <= 50)]['total_line_items_price'], ax=ax1, bins=50, stat='probability', color='green', label='10 < discounts <= 50', kde=True);\nsns.histplot(orders.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: x['total_discounts'] > 50]['total_line_items_price'], ax=ax1, bins=50, stat='probability', color='purple', label='discounts > 50', kde=True);\nax1.legend(['no discounts', 'discounts <= 10', '10 < discounts <= 50', 'discounts > 50'])\nax1.set_xlabel('Order Items Total Price')\n\nsns.histplot(prod_order.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: x['total_discounts'] == 0].groupby(['order_id'])['quantity'].sum(), ax=ax2, bins=30, stat='probability', color='red', label='no discounts', kde=True);\nsns.histplot(prod_order.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: (x['total_discounts'] > 0) & (x['total_discounts'] <= 10)].groupby(['order_id'])['quantity'].sum(), ax=ax2, bins=30, stat='probability', color='yellow', label='discounts <= 10', kde=True);\nsns.histplot(prod_order.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: (x['total_discounts'] > 10) & (x['total_discounts'] <= 50)].groupby(['order_id'])['quantity'].sum(), ax=ax2, bins=30, stat='probability', color='green', label='10 < discounts <= 50', kde=True);\nsns.histplot(prod_order.loc[lambda x: x['order_id'].isin(target_order_ids)].loc[lambda x: x['total_discounts'] > 50].groupby(['order_id'])['quantity'].sum(), ax=ax2, bins=30, stat='probability', color='purple', label='discounts > 50', kde=True);\nax2.legend(['no discounts', 'discounts <= 10', '10 < discounts <= 50', 'discounts > 50'])\nax2.set_xlabel('Order Items Quantity');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Customer Analysis - Churn"},{"metadata":{},"cell_type":"markdown","source":"* Overall Churn  "},{"metadata":{"trusted":true},"cell_type":"code","source":"orders['y_m'] = orders['order_created_at'].apply(lambda x: x[:7])\noverall_churn = orders.groupby(['y_m'])['customer_id'].nunique().reset_index().rename(columns={'customer_id':'current_month_num_customers'}) # consider a customer may place orders at the same day, nunique() is used\noverall_churn['previous_month_num_customers'] = overall_churn['current_month_num_customers'].shift(1)\n#overall_churn['current_month_1st_day_num_customers'] = pd.Series(orders.groupby(['y_m', 'order_created_at'])['customer_id'].nunique().reset_index().groupby(['y_m'])['customer_id'].first().tolist())\n#overall_churn['current_month_last_day_num_customers'] = pd.Series(orders.groupby(['y_m', 'order_created_at'])['customer_id'].nunique().reset_index().groupby(['y_m'])['customer_id'].last().tolist())\n\noverall_churn['num_churns'] = overall_churn['previous_month_num_customers'] - overall_churn['current_month_num_customers']\noverall_churn['churn_rate'] = overall_churn['num_churns'] / overall_churn['previous_month_num_customers']\noverall_churn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 5))\n\nsns.barplot(overall_churn['y_m'], overall_churn['churn_rate'])\n#plt.title('Churn rate over month', size=20)\nax.tick_params(axis='x', rotation=30)\nplt.ylabel('churn rate')\nplt.xlabel('year-month');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Customer-level Churn (Customers without purchase in the current and previous 3 months is called churn)"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_journey = []\nfor cus in customers['customer_id'].unique():\n    cus_1st_day = customers.loc[lambda x: x['customer_id'] == cus, 'customer_created_at'].values[0]\n    for t in orders.loc[lambda x: x['order_created_at'] >= cus_1st_day]['order_created_at'].unique():\n        customer_journey.append([cus, t])\n        \ncustomer_journey = pd.DataFrame(customer_journey, columns=['customer_id', 'date'])\ncustomer_journey = pd.merge(customers[['customer_id', 'customer_created_at']], customer_journey, on='customer_id')\n\ncustomer_order = (pd.merge(customer_journey, \n                           orders, \n                           left_on=['customer_id', 'date'],\n                           right_on=['customer_id', 'order_created_at'], \n                           how='left')\n                  [['customer_id', 'customer_created_at', 'date', 'order_created_at']]\n                  .sort_values(by=['order_created_at', 'customer_id']))\n\ncustomer_order['y_m'] = customer_order['date'].apply(lambda x: x[:7] if type(x) == str else x)\ncustomer_order","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_order['is_purchased'] = customer_order['order_created_at'].apply(lambda x: 1 if type(x) == str else 0)\ncustomer_churn = customer_order.groupby(['customer_id', 'y_m']).agg({'customer_created_at':'first', 'is_purchased':'sum'}).rename(columns={'is_purchased':'num_order'}).reset_index()\ncustomer_churn['prev_num_order'] = customer_churn.groupby(['customer_id']).apply(lambda x: x['num_order'].shift(1)).tolist()\ncustomer_churn['2nd_prev_num_order'] = customer_churn.groupby(['customer_id']).apply(lambda x: x['num_order'].shift(2)).tolist()\ncustomer_churn['3rd_prev_num_order'] = customer_churn.groupby(['customer_id']).apply(lambda x: x['num_order'].shift(3)).tolist()\n\ncustomer_churn['is_current_month_active'] = customer_churn['num_order'].apply(lambda x: 1 if x > 0 else 0)\ncustomer_churn['is_prev_month_active'] = customer_churn['prev_num_order'].apply(lambda x: 1 if x > 0 else 0)\ncustomer_churn['is_2nd_prev_month_active'] = customer_churn['2nd_prev_num_order'].apply(lambda x: 1 if x > 0 else 0)\ncustomer_churn['is_3rd_prev_month_active'] = customer_churn['3rd_prev_num_order'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_churn = customer_churn.drop(columns=['status'], errors='ignore')\ncustomer_churn['total_num_order'] = pd.Series(customer_churn.groupby(['customer_id'])['num_order'].cumsum().tolist())\n\ncustomer_churn.loc[lambda x: \n                   (x['is_current_month_active'] == 0) & \n                   (x['is_prev_month_active'] == 0) & \n                   (x['is_2nd_prev_month_active'] == 0) & \n                   (x['is_3rd_prev_month_active'] == 0), 'status'] = 'churn'\n\ncustomer_churn.loc[lambda x: \n                   (x['is_current_month_active'] == 1) | \n                   (x['is_prev_month_active'] == 1) |\n                   (x['is_2nd_prev_month_active'] == 1) |\n                   (x['is_3rd_prev_month_active'] == 1), 'status'] = 'active'\n\ncustomer_churn.loc[lambda x: \n                   (x['is_current_month_active'] == 1) & \n                   (x['is_prev_month_active'] == 1) &\n                   (x['is_2nd_prev_month_active'] == 1) &\n                   (x['is_3rd_prev_month_active'] == 1), 'status'] = 'loyal'\n\ncustomer_churn.loc[lambda x: x['total_num_order'] == 0, 'status'] = 'have_not_purchased'\n\ncustomer_churn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn = pd.pivot_table(customer_churn[['y_m', 'status']],\n                       index=['y_m'],\n                       columns=['status'],\n                       aggfunc=lambda x: len(x),\n                       fill_value=0).reset_index()\nchurn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))\n\nsns.barplot(churn['y_m'], churn['churn'], ax=ax1)\nplt.text(x=1.5, \n         y=25000, \n         s='Churn: customers who have made purchases \\n            but not having any purchase in the \\n            current and the previous 3 months', \n         fontfamily='fantasy', \n         fontsize=15, \n         fontweight=5,\n         bbox={'boxstyle':'round', 'facecolor':'none', 'edgecolor':'black'})\nax1.tick_params(axis='x', rotation=15)\nax1.set_ylabel('cumulative churns')\nax1.set_xlabel('year-month');\n\nsns.lineplot(data=churn, x='y_m', y='active', ax=ax2, label='active', linewidth=3, color='green')\nsns.lineplot(data=churn, x='y_m', y='churn', ax=ax2, label='churn', linewidth=3, color='red')\nsns.lineplot(data=churn, x='y_m', y='have_not_purchased', ax=ax2, label='have not purchased', linewidth=3, color='grey')\nsns.lineplot(data=churn, x='y_m', y='loyal', ax=ax2, label='loyal', linewidth=3, color='gold')\nax2.set_ylabel('number of customers')\nax2.set_xlabel('year-month')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Customer Analysis - Retention"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_churn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_churn['cohert'] = customer_churn['customer_created_at'].apply(lambda x: x[:7])\nretention = pd.pivot_table(customer_churn.loc[lambda x: x['num_order'] != 0], # here we drop all the customers who didn't place order in certain months\n                           index=['y_m'],\n                           columns=['cohert'],\n                           values=['customer_id'],\n                           aggfunc=lambda x: x.nunique(),\n                           fill_value=0).reset_index()\nretention.columns = ['y_m'] + [col[1] for col in retention.columns[1:]]\nretention","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 10))\nplt.xticks(ticks=np.arange(len(retention['y_m'])), labels=retention['y_m'], rotation=30)\nplt.xlabel('Year-Month')\nplt.ylabel('Cumulative Number of Active Customers')\n\nretentions_data_list = []\nfor i in range(2, len(retention.columns)):\n    data = retention.iloc[i-2:, 1:i]\n    retentions_data_list.append(data)\n    sns.lineplot(x=data.index, y=data.sum(axis=1), color=sns.color_palette(\"deep\", n_colors=30)[i-2], label='+cohert ' + str(i - 1), linewidth=2)\n\nfig, ax2 = plt.subplots(figsize=(15, 10)) \nax2.set_xlim((-1, 20))\nplt.xticks(ticks=np.arange(len(retention['y_m'])), labels=retention['y_m'], rotation=30)\nplt.xlabel('Year-Month')\nplt.ylabel('Cumulative Number of Active Customers')\n\nretentions_data_list.reverse()\nfor i, data in enumerate(retentions_data_list):\n    sns.barplot(x=data.index, y=data.sum(axis=1), color=sns.color_palette(\"deep\", n_colors=30)[18 - i], label='+cohert ' + str(i+1), linewidth=2, alpha=0.9)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_retention = pd.DataFrame(retention['y_m'])\nfor i, col in enumerate(retention.columns[1:]):\n    data = retention.loc[i:, col].reset_index(drop=True)\n    customer_retention = pd.concat([customer_retention, data], axis=1)\n\nfor col in customer_retention.columns[1:]:\n    if customer_retention[col].max() > 1:\n        customer_retention[col] = np.round(customer_retention[col] / customer_retention[col].max(), 4)\ncustomer_retention = customer_retention.drop(columns=['y_m'])\ncustomer_retention","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,9))\nfig.tight_layout()\nax = sns.heatmap(customer_retention, annot=True, cmap=\"YlGnBu\", fmt='.0%')\n\nax.set_xlabel('Cohort Period', fontsize = 15)\nax.set_ylabel('Cohort Group', fontsize = 15)\n\nax.set_title('Retention Rates Across Cohorts', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Customer Analysis - RFM"},{"metadata":{},"cell_type":"markdown","source":"* In order to improve the retention rate, we need to get a better understanding of the old customers.\n* Instead of analyzing the entire customer base as a whole, itâ€™s better to segment them into homogeneous groups, understand the traits of each group, and engage them with relevant campaigns rather than segmenting on just customer age or geography.\n* One of the most popular, easy-to-use, and effective segmentation methods to enable marketers to analyze customer behavior is RFM analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm = (orders\n       .groupby(['customer_id'])\n       .agg({'order_created_at': lambda x: (orders['order_created_at'].astype('datetime64[ns]').dt.date.max() - x.astype('datetime64[ns]').dt.date.max()).days,\n             'order_id': lambda x: len(x),\n             'total_price': lambda x: x.sum()})\n       .rename(columns={'order_created_at':'recency',\n                        'order_id':'frequency',\n                        'total_price':'monetary'})\n       .reset_index()\n       .loc[lambda x: x['customer_id'] != 280479208957] # this is a wierd: customer 280479208957 made 355 orders, which is also an outlier\n      )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(10, 10))\nfig.tight_layout()\nsns.histplot(data=rfm, x='recency', stat='probability', bins=50, kde=True, color='red', ax=ax1)\nsns.histplot(data=rfm, x='frequency', stat='probability', bins=50, kde=True, color='orange', ax=ax2)\nsns.histplot(data=rfm, x='monetary', stat='probability', bins=50, kde=True, color='green', ax=ax3);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rfm_to_score(df, col, q=[0, 0.25, 0.5, 0.75, 1], labels=[1, 2, 3, 4]):\n    \"\"\"Convert RFM to scores. \"\"\"\n    if col == 'recency':\n        return pd.qcut(-df[col], q=q, labels=labels)\n    elif col == 'monetary':\n        return pd.qcut(df[col], q=q, labels=labels)\n    elif col == 'frequency':\n        return df[col].apply(lambda x: 1 if x <= 1 else 4)\n    else: \n        print('column not applied...')\n        pass\n\nrfm['R'] = rfm_to_score(rfm, col='recency')\nrfm['F'] = rfm_to_score(rfm, col='frequency')\nrfm['M'] = rfm_to_score(rfm, col='monetary')\n\nrfm['RFMGroup'] = rfm['R'].astype(str) + '/' + rfm['F'].astype(str) + '/' + rfm['M'].astype(str)\nrfm['RFMScore'] = rfm[['R', 'F', 'M']].sum(axis = 1)\nrfm['loyalty_by_rfm'] = pd.qcut(rfm['RFMScore'], q=[0, 0.25, 0.5, 0.75, 1], labels=['bronze', 'silver', 'gold', 'platinum'])\nrfm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm.loc[rfm['R'] == 4].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 10))\nax1 = fig.add_subplot(3, 3, 1)\nax2 = fig.add_subplot(3, 3, 2)\nax3 = fig.add_subplot(3, 3, 3)\nsns.histplot(data=rfm, x='R', bins=50, color='red', ax=ax1, binwidth=0.5, discrete=True)\nsns.histplot(data=rfm, x='F', bins=50, color='orange', ax=ax2, binwidth=0.5, discrete=True)\nsns.histplot(data=rfm, x='M', bins=50, color='green', ax=ax3, binwidth=0.5, discrete=True)\nax4 = fig.add_subplot(3, 1, 2)\nsns.histplot(data=rfm, x='RFMScore', bins=50, color='blue', ax=ax4, discrete=True)\nax5 = fig.add_subplot(3, 1, 3)\nsns.barplot(data=rfm['loyalty_by_rfm'].value_counts(normalize=True).reset_index(), x='index', y='loyalty_by_rfm', ax=ax5, edgecolor=(0, 0, 0))\nax5.set_xlabel('Customer Tiers')\nax5.set_ylabel('Percentage')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Customer Analysis - Segmentation by Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_seg = rfm.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# avg. number of days placing order \ncustomer_seg = customer_seg.drop(columns=['avg_num_days_to_place_another_order'], errors='ignore')\ncustomer_order['order_created_at'] = customer_order['order_created_at'].astype('datetime64[ns]')\ncustomer_order['prev_order_created_at'] = customer_order.sort_values(by=['customer_id', 'order_created_at']).groupby(['customer_id'])['order_created_at'].apply(lambda x: x.shift(1))\ncustomer_order['num_days_btwn_orders']  = (customer_order['order_created_at'] - customer_order['prev_order_created_at']).dt.days\n\ncustomer_seg = rfm.copy()\ncustomer_seg = customer_seg.merge(customer_order\n                                  .groupby(['customer_id'])['num_days_btwn_orders'].mean()\n                                  .reset_index()\n                                  .rename(columns={'num_days_btwn_orders':'avg_num_days_to_place_another_order'})\n                                  .fillna(0),\n                                  on='customer_id')\n\ncustomer_seg['avg_num_days_to_place_another_order'] = customer_seg['avg_num_days_to_place_another_order'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# num refund\ncustomer_seg = customer_seg.drop(columns=['num_refund'], errors='ignore')\ncustomer_seg = (\ncustomer_seg.merge(pd.merge(customer_order, \n                            orders[['customer_id', 'order_id']], \n                            on='customer_id')\n                   .merge(transactions[['order_id', 'transaction_amount', 'transaction_kind', 'transaction_status']], \n                          on='order_id')\n                   .loc[lambda x: x['transaction_kind'] == 'refund']\n                   .groupby(['customer_id'])['order_id'].nunique()\n                   .reset_index()\n                   .rename(columns={'order_id':'num_refund'}),\n                   on='customer_id',\n                   how='left')\n)\ncustomer_seg['num_refund'] = customer_seg['num_refund'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# num void or failure\ncustomer_seg = customer_seg.drop(columns=['num_transaction_void_failure'], errors='ignore')\ncustomer_seg = (\ncustomer_seg.merge(pd.merge(customer_order, \n                            orders[['customer_id', 'order_id']], \n                            on='customer_id')\n                   .merge(transactions[['order_id', 'transaction_amount', 'transaction_kind', 'transaction_status', 'error_code']], \n                          on='order_id')\n                   .loc[lambda x: \n                        (x['transaction_kind'] == 'void') | \n                        (x['transaction_status'].isin(['failure', 'error'])) |\n                        (~x['error_code'].isnull())]\n                   .groupby(['customer_id'])['order_id'].nunique()\n                   .reset_index()\n                   .rename(columns={'order_id':'num_transaction_void_failure'}),\n                   on='customer_id',\n                   how='left')\n)\ncustomer_seg['num_transaction_void_failure'] = customer_seg['num_transaction_void_failure'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_seg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_list = ['recency', 'frequency', 'monetary', 'avg_num_days_to_place_another_order', 'num_refund', 'num_transaction_void_failure']\nstd_scaler = StandardScaler()\ncluster_data = pd.DataFrame(std_scaler.fit_transform(customer_seg[col_list]), \n                            index=customer_seg.index,\n                            columns=col_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_of_sq_dist = {}\nfor k in range(1,15):\n    kmeans = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n    kmeans = kmeans.fit(cluster_data)\n    sum_of_sq_dist[k] = kmeans.inertia_\n    \n#Plot the graph for the sum of square distance values and Number of Clusters\nplt.figure(figsize=(10, 5))\nsns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()))\nplt.xlabel('Number of Clusters(k)')\nplt.ylabel('Sum of Square Distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build the K-Means clustering model\nkmeans = KMeans(n_clusters= 5, init= 'k-means++', max_iter= 1000, random_state=42)\nkmeans.fit(cluster_data)\n\ncustomer_seg['cluster'] = kmeans.labels_\ncustomer_seg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_seg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3d scatterplot using plotly\nscene = {'xaxis':{'title':'Recency'},\n         'yaxis':{'title':'Frequency'},\n         'zaxis':{'title':'Monetary'}}\n\ncluster_0 = go.Scatter3d(x=customer_seg.loc[lambda x: x['cluster'] == 0]['recency'], \n                         y=customer_seg.loc[lambda x: x['cluster'] == 0]['frequency'], \n                         z=customer_seg.loc[lambda x: x['cluster'] == 0]['monetary'], \n                         name='cluster 1', \n                         mode='markers', \n                         marker={'color':0,\n                                 'size':10,\n                                 'line':{'color':'black', \n                                         'width':10}})\n\ncluster_1 = go.Scatter3d(x=customer_seg.loc[lambda x: x['cluster'] == 1]['recency'], \n                         y=customer_seg.loc[lambda x: x['cluster'] == 1]['frequency'], \n                         z=customer_seg.loc[lambda x: x['cluster'] == 1]['monetary'],\n                         name='cluster 2', \n                         mode='markers', \n                         marker={'color':1,\n                                 'size':10,\n                                 'line':{'color':'black', \n                                         'width':10}})\n\ncluster_2 = go.Scatter3d(x=customer_seg.loc[lambda x: x['cluster'] == 2]['recency'], \n                         y=customer_seg.loc[lambda x: x['cluster'] == 2]['frequency'], \n                         z=customer_seg.loc[lambda x: x['cluster'] == 2]['monetary'], \n                         name='cluster 3', \n                         mode='markers', \n                         marker={'color':2,\n                                 'size':10,\n                                 'line':{'color':'black', \n                                         'width':10}})\n\ncluster_3 = go.Scatter3d(x=customer_seg.loc[lambda x: x['cluster'] == 3]['recency'], \n                         y=customer_seg.loc[lambda x: x['cluster'] == 3]['frequency'], \n                         z=customer_seg.loc[lambda x: x['cluster'] == 3]['monetary'], \n                         name='cluster 4', \n                         mode='markers', \n                         marker={'color':3,\n                                 'size':10,\n                                 'line':{'color':'black', \n                                         'width':10}})\n\ncluster_4 = go.Scatter3d(x=customer_seg.loc[lambda x: x['cluster'] == 4]['recency'], \n                         y=customer_seg.loc[lambda x: x['cluster'] == 4]['frequency'], \n                         z=customer_seg.loc[lambda x: x['cluster'] == 4]['monetary'], \n                         name='cluster 5', \n                         mode='markers', \n                         marker={'color':4,\n                                 'size':10,\n                                 'line':{'color':'black', \n                                         'width':10}})\n\nlayout = go.Layout(margin={'l':0, 'r':0},\n                   scene=scene,\n                   height=800,\n                   width=800)\n\nfig = go.Figure(data = [cluster_0, cluster_1, cluster_2, cluster_3, cluster_4], layout = layout)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}